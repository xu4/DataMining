{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6ad807c7740f69aeef5fa7e3666fdf51",
     "grade": false,
     "grade_id": "cell-f433e33eab3c82f5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.2.033020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8783b067e7d492616519fa42cc3ad3f9",
     "grade": false,
     "grade_id": "cell-a7fb49948b186646",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 2: Mining Itemsets (Part II)\n",
    "\n",
    "## Finding Frequent Itemsets with Apriori\n",
    "\n",
    "In Part I of this assignment, the summary statistics gave us a brief view of what the data look like. Now it is time for the real business - let's use the *Apriori* algorithm to find the frequent itemsets. \n",
    "First, let's import the packages and dependencies that will be used in this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f8364179b8d0f8265d9cb1d77785260",
     "grade": false,
     "grade_id": "cell-44958ea23aaa6438",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "176a6f4022f255e447edb5d25c11a290",
     "grade": false,
     "grade_id": "cell-02805d21e9adc093",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**<span style=\"color:red\">NOTE: These are all the imports we need to make for this assignment. You should not make other imports in your submitted notebook. You will receive 0 points for the exercises if your solution includes additional imports.</span>**\n",
    "\n",
    "Before you practice Apriori on the tasty emojis, let's use another dataset as an example to get familiar with the algorithm. As you can see, this is a data set of shopping history - every row is a shopping basket and every column is a product item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "467b4888e777e247f03ad1f76b14058b",
     "grade": false,
     "grade_id": "cell-dfc2fdf45a0070d2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "market_df = pd.read_csv('assets/shopping_basket.csv')\n",
    "market_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "97a76e2f702560c330c0049ea3a1f73f",
     "grade": false,
     "grade_id": "cell-8e190e9a8894a712",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print(market_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2e2bc452860b62fdd4e10a493e355989",
     "grade": false,
     "grade_id": "cell-32f0579c8e0af34c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "We can call the Apriori API now and specify the minimal support we want. You may learn more about this API from its [documentation](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "773fbff06a02beb6dddefc447922c60a",
     "grade": false,
     "grade_id": "cell-69e1dbba3eb67f60",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "market_frequent_itemsets = apriori(market_df, min_support=0.005, use_colnames=True)\n",
    "market_frequent_itemsets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "910311fcc8403b8493dc5c60a91be324",
     "grade": false,
     "grade_id": "cell-33456a784d1c91ea",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "With the above command, we find all itemsets with a min support of 0.005 (half percent of the shopping baskets). We can now use the following command to extract the frequent itemsets with length 2 and beyond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d3ee6d23cd91609800c73e1cfb86b875",
     "grade": false,
     "grade_id": "cell-781c17b9fc27de6f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "market_frequent_itemsets[market_frequent_itemsets['itemsets'].apply(lambda x: len(x)) > 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3d3421b4261d038fa7a501a48254d8fc",
     "grade": false,
     "grade_id": "cell-888e0e97a23c6fdd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "**Now, it is time to apply the Apriori algorithm to the emoji dataset.**\n",
    "\n",
    "Since we have already shown you how to transform the Tweets into emoji itemsets, we concatenate the data preprocessing code into one block. Please run the following code block to load and preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "99da44983d2e501a7873c12c945830c7",
     "grade": false,
     "grade_id": "cell-3afcb9ca820e6f20",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv(\"assets/food_drink_emoji_tweets.txt\", sep=\"\\t\", header=None)\n",
    "tweets_df.columns = ['text']\n",
    "\n",
    "emoji_list = \"ðŸ‡ðŸˆðŸ‰ðŸŠðŸ‹ðŸŒðŸðŸ¥­ðŸŽðŸðŸðŸ‘ðŸ’ðŸ“ðŸ¥ðŸ…ðŸ¥¥ðŸ¥‘ðŸ†ðŸ¥”ðŸ¥•ðŸŒ½ðŸŒ¶ðŸ¥’ðŸ¥¬ðŸ¥¦ðŸ„ðŸ¥œðŸŒ°ðŸžðŸ¥ðŸ¥–ðŸ¥¨ðŸ¥¯ðŸ¥žðŸ§€ðŸ–ðŸ—ðŸ¥©ðŸ¥“ðŸ”ðŸŸðŸ•ðŸŒ­ðŸ¥ªðŸŒ®ðŸŒ¯ðŸ¥™ðŸ¥šðŸ³ðŸ¥˜ðŸ²ðŸ¥£ðŸ¥—ðŸ¿ðŸ§‚ðŸ¥«ðŸ±ðŸ˜ðŸ™ðŸšðŸ›ðŸœðŸðŸ ðŸ¢ðŸ£ðŸ¤ðŸ¥ðŸ¥®ðŸ¡ðŸ¥ŸðŸ¥ ðŸ¥¡ðŸ¦€ðŸ¦žðŸ¦ðŸ¦‘ðŸ¦ðŸ§ðŸ¨ðŸ©ðŸªðŸŽ‚ðŸ°ðŸ§ðŸ¥§ðŸ«ðŸ¬ðŸ­ðŸ®ðŸ¯ðŸ¼ðŸ¥›â˜•ðŸµðŸ¶ðŸ¾ðŸ·ðŸ¸ðŸ¹ðŸºðŸ»ðŸ¥‚ðŸ¥ƒ\"\n",
    "emoji_set = set(emoji_list)\n",
    "\n",
    "tweets_df['emojis'] = tweets_df.text.apply(lambda text:np.unique([chr for chr in text if chr in emoji_set]))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "emoji_matrix = pd.DataFrame(data=mlb.fit_transform(tweets_df.emojis), index=tweets_df.index, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a41a5dacbaf4b4f30dd07a6ace454313",
     "grade": false,
     "grade_id": "cell-ce1ef7e3e490922a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2.  (20 pts)\n",
    "Complete the following `emoji_frequent_itemsets` function to find all the **frequent *k*-itemsets** with a minimal support of **`min_support`** in the emoji dataset. \n",
    "\n",
    "Your function should return a Pandas DataFrame object similar to the `market_frequent_itemsets` object above. The DataFrame object should have two columns: \n",
    "- The first one is named `support` and stores the support of the frequent itemsets. \n",
    "- The second column is named `itemsets` and stores the frequent itemset as a *frozenset* (the default return type of the apriori API).\n",
    "\n",
    "Make sure that you are only returning the frequent itemsets that have the specified number of emojis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "13850969e6584e681b161d85472ca07a",
     "grade": false,
     "grade_id": "cell-6284eb431d85af5d",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def emoji_frequent_itemsets(emoji_matrix, min_support=0.005, k=3):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b275d7dbb532e14daa284ee7af0001d6",
     "grade": false,
     "grade_id": "cell-d7c33b01ae23f692",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If you implemented this function correctly, we can obtain all frequent 3-itemsets with a min support of 0.005 by running the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_frequent_3itemsets = emoji_frequent_itemsets(emoji_matrix, min_support=0.005, k=3)\n",
    "# You can uncomment the following line to view the obtained frequent itemsets.\n",
    "# emoji_frequent_3itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "36c22c534e6119cf1f6f7b893ca914fc",
     "grade": true,
     "grade_id": "cell-80c14c6071ed14f7",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell test whether the `emoji_frequent_itemsets` function is implemented correctly.\n",
    "# We hide some tests, so passing all the displayed assertions does not guarantee full points.\n",
    "\n",
    "emoji_frequent_3itemsets = emoji_frequent_itemsets(emoji_matrix, min_support=0.005, k=3)\n",
    "for row in emoji_frequent_3itemsets.itertuples():\n",
    "    assert row.support >= 0.005, f\"[Exercise 2] The support of the itemset {row.itemsets} is below the threshold.\"\n",
    "    assert len(row.itemsets) == 3, f\"[Exercise 2] The itemset {row.itemsets} is not a 3-itemset.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "77ddb703774ac598e088e269af0c3d60",
     "grade": false,
     "grade_id": "cell-552898e0b750fe65",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "If you are interested, you may also examine what the frequent 4-itemsets look like. Does the result make sense to you? (This part will not be graded.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f34f83cdacf4f7349644bb8702711391",
     "grade": false,
     "grade_id": "cell-3aa92ec6b476e7b3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "emoji_frequent_4itemsets = emoji_frequent_itemsets(emoji_matrix, min_support=0.005, k=4)\n",
    "emoji_frequent_4itemsets"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_data_mining_i_v2_assignment2_part2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
