{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "da4d1226ee5528f4965345339c219993",
     "grade": false,
     "grade_id": "cell-490533171bea2bb9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.2.033020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c909e636dd7ed607750bb6192c759821",
     "grade": false,
     "grade_id": "cell-5599af242e342483",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4: Mining Sequence Data (Part III)\n",
    "\n",
    "## Detecting Near Duplicates\n",
    "\n",
    "Sequence similarity metrics can be widely applied to many tasks. In this last part of the assignment, let's look at another application of sequence similarity -- detecting near-duplicates.  Near-duplicate detection is commonly used in plagiarism detection, index selection for search engines, copy-paste detection, biological sequence alignments, and beyond.  Edit distance is still a viable solution to these problems, but when we are dealing with longer sequences, the efficiency becomes a big issue. Unfortunately, edit distance has to fill in the $n$ by $n$ table - in other words, it has a time complexity of O(n^2). This can't scale up. Shingling is a much more efficient solution. \n",
    "\n",
    "Following the introduction of *shingling* in the lecture, let's practice it on our Twitter dataset. The *shingling* approach relies on $n$-grams and Jaccard similarity. Luckily, we have already been familiar with both.\n",
    "\n",
    "First, let's import the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e8fc2470315727d27ebb2810f5414ccd",
     "grade": false,
     "grade_id": "cell-caf2d26944e2c436",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "24e26393276a02a390802f010ecaa177",
     "grade": false,
     "grade_id": "cell-448f4373d8517524",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 4. Shingling (20 pts)\n",
    "\n",
    "Complete the `shingling_jaccard_similarity` function to compute the similarity score between two pieces of text using the shingling approach. Specifically, you should (1) represent both text sequences as sets of overlapping $n$-grams ($n$ specified as an argument) and (2) compute the Jaccard similarity between the two sets. We have implemented a `jaccard_similarity` function for your convenience. \n",
    "\n",
    "**Hint**: \n",
    "1. You may use the `nltk.ngrams` API to obtain the $n$-grams. \n",
    "2. The `nltk.ngrams` API returns an iterator of tuples. You may wrap it up with `list()` to collect the $n$-grams as a list. You may checkout how we use `nltk.bigrams` in Part 1 of this assignment as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "96327b65adcccf66d6d29f4f8ee6fc4c",
     "grade": false,
     "grade_id": "cell-c1fbf0cc8d8a1fb8",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.casual.TweetTokenizer()\n",
    "\n",
    "def jaccard_similarity(list_x, list_y):\n",
    "    set_x = set(list_x)\n",
    "    set_y = set(list_y)\n",
    "    intersection = set_x.intersection(set_y)\n",
    "    union = set_x.union(set_y)\n",
    "    return len(intersection) / len(union) if len(union) > 0 else 0\n",
    "\n",
    "def shingling_jaccard_similarity(text_x, text_y, n):\n",
    "    ngram_x = list(nltk.ngrams(tokenizer.tokenize(text_x), n))\n",
    "    ngram_y = list(nltk.ngrams(tokenizer.tokenize(text_y), n))\n",
    "    \n",
    "    return jaccard_similarity(ngram_x, ngram_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d49ab4b71534dc8c3b9e5d19a35dc8e2",
     "grade": false,
     "grade_id": "cell-a83fb51de35f752c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You may try out the examples used in the lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "x = \"to be or not to be\"\n",
    "y = \"not be or not to be\"\n",
    "z = \"be or not to not be\"\n",
    "\n",
    "print(shingling_jaccard_similarity(x,y, 3))\n",
    "print(shingling_jaccard_similarity(x,z, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ffe31eb72e43a4bc1d0d508624be8890",
     "grade": true,
     "grade_id": "cell-6a85aa6fc8198106",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This code block tests if the `shingling_jaccard_similarity` function is implemented correctly\n",
    "# We hide some tests. Passing the displayed assertions does not guarantee full points.\n",
    "\n",
    "x = \"to be or not to be\"\n",
    "y = \"not be or not to be\"\n",
    "z = \"be or not to not be\"\n",
    "\n",
    "assert abs(shingling_jaccard_similarity(\"to be or not to be\", \"not be or not to be\", 3) - 0.6) < 1e-8\n",
    "assert abs(shingling_jaccard_similarity(\"to be or not to be\", \"be or not to not be\", 3) - 1/3) < 1e-8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4234b3fdf861050ea141fae98dfabd67",
     "grade": false,
     "grade_id": "cell-513254bdd0ed11a7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Now let's see how this similarity function can help us detect near-duplicate Tweets in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c4572f09607b6aa2eabec7321e38e41f",
     "grade": false,
     "grade_id": "cell-26c0489799db4862",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv(\"assets/tweets.txt\", sep=\"\\t\", header=None)\n",
    "tweet_df.columns = ['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5392f8fdf96072e85083415aca9e7319",
     "grade": false,
     "grade_id": "cell-834022645f7a6b56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "One of the Tweet that caught our attention has the index of 220."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "31642d073169e1fa6b17ef0823ecfb4f",
     "grade": false,
     "grade_id": "cell-b80cfb749ac68a4c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @malangangels ğŸ­ ğŸ¸ Malang ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/vS1Oukm3yq\n"
     ]
    }
   ],
   "source": [
    "print(tweet_df.loc[220].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0f0bcb1c1f7d9d11bc1645d51c3c8529",
     "grade": false,
     "grade_id": "cell-eed39a242b4b39ee",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's see whether we can find near duplicates of this Tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48a0ebb9f0db669c14170c88acb42954",
     "grade": false,
     "grade_id": "cell-5f21b4241d94de5c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>#TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @malangangel...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4906</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>#TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @VaniaBDG_2 ...</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>#TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @Lanci_Mevit...</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5118</th>\n",
       "      <td>RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...</td>\n",
       "      <td>0.346154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6575</th>\n",
       "      <td>Case of the Monday Blues? Nothing a KNOW Bette...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6577</th>\n",
       "      <td>RT @LunnMiss: #TwinPeaks ğŸŒ²ğŸ¦‰ğŸŒ² Â«Fire Walk With M...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text       sim\n",
       "220   #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @malangangel...  1.000000\n",
       "2342  RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...  0.750000\n",
       "4906  RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...  0.521739\n",
       "2280  RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...  0.521739\n",
       "2323  #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @VaniaBDG_2 ...  0.391304\n",
       "6109  #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @Lanci_Mevit...  0.375000\n",
       "3651  RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...  0.346154\n",
       "5118  RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­...  0.346154\n",
       "6575  Case of the Monday Blues? Nothing a KNOW Bette...  0.000000\n",
       "6577  RT @LunnMiss: #TwinPeaks ğŸŒ²ğŸ¦‰ğŸŒ² Â«Fire Walk With M...  0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df['sim'] = tweet_df.text.apply(lambda x: shingling_jaccard_similarity(tweet_df.loc[220].text, x, 3))\n",
    "tweet_df.sort_values('sim', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6128532472a8feab43e7b7c3e1a93252",
     "grade": false,
     "grade_id": "cell-c157db906d710ffd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @malangangels ğŸ­ ğŸ¸ Malang ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/vS1Oukm3yq\n",
      "RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @malangangels ğŸ­ ğŸ¸ Malang ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/dV3ibBQhar\n",
      "RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @malangvhi ğŸ­ ğŸ¸ Malang ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/tyqGu1id2S\n",
      "RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @KimiMlg ğŸ­ ğŸ¸ Malang ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/1SIagPPTAP\n",
      "#TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @VaniaBDG_2 ğŸ­ ğŸ¸ Bandung ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/82ZT2nv2Py\n",
      "#TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @Lanci_Mevita ğŸ­ ğŸ¸ Expo Cirebon ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/KCyJE4cqH3\n",
      "RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @AmorPutri96 ğŸ­ ğŸ¸ Bandung ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/GHNSo7Qc1U\n",
      "RT @dunk_sl: #TopListAngels ğŸ‘  Ready For BO ğŸ‘  ğŸ­ @AmorPutri96 ğŸ­ ğŸ¸ Bandung ğŸ¸ ğŸ’° dan â˜ by DM https://t.co/XeNo4Dal2A\n",
      "Case of the Monday Blues? Nothing a KNOW Better cookie &amp; cup of joe can't fix.ğŸª â˜•ï¸ #CookiesandCoffee #yummy\n",
      "RT @LunnMiss: #TwinPeaks ğŸŒ²ğŸ¦‰ğŸŒ² Â«Fire Walk With MeÂ» Ğrt.Dan May @Kyle_MacLachlan â˜•ï¸ğŸ¥§â˜•ï¸ @mfrost11ğŸ”¥ğŸ’”ğŸ”¥ @DAVID_LYNCH @LynchFoundation https://â€¦\n"
     ]
    }
   ],
   "source": [
    "near_dups = tweet_df.sort_values('sim', ascending=False).head(10)\n",
    "for x in list(near_dups.text):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c298ed9ea80a383d07e105d25eb21550",
     "grade": false,
     "grade_id": "cell-23640c18ea7b52e9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Indeed, we see that the top-8 Tweets look very similar! In fact, many of them are Retweets of the original Tweet, with only small variations on the user handler and/or URLs - so they are indeed near-duplicates. This concludes this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "41a894b0507adbdfc3bff058715d5e94",
     "grade": false,
     "grade_id": "cell-8d621b618ebed079",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "You have probably noted that although shingling is faster than edit distance, computing the similarity to every other Tweet can still still time consuming (and not necessary if we only care about near-duplicates). In some applications you'll have to compute the similarity between every pair of text, which is even more inefficient.  Sometimes we have to compare very long sequences, too (the total length of the human genome is over 3 billion base pairs). There are tricks to greatly speed up similarity computation (by only comparing a fingerprint of the shingles and only evaluating promising pairs),  known as MinHash and Locality Sensitive Hashing (LSH), which are usually used in combination with shingling.  They are beyond the scope of this course, but we encourage you to read on (http://infolab.stanford.edu/~ullman/mmds/ch3.pdf) and consider using them when you have a large data set in hand! You may find an open-source implementation at https://github.com/ekzhu/datasketch."
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_data_mining_i_v2_assignment4_part3"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
