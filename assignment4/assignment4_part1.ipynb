{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d1832634730ce5be48e050462853b31f",
     "grade": false,
     "grade_id": "cell-d5d1ffd2e65cc798",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "version = \"v2.2.033020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "011f2a31f5eccb46a22e913b45621a63",
     "grade": false,
     "grade_id": "cell-2ab9369766ad00a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4: Mining Sequence Data (Part I)\n",
    "\n",
    "Welcome to Assignment 4, the last assignment in this course. In this assignment, we will explore the sequence representation of data. Lots of real-world data can be represented as sequences. Among them, text data is typical and widely available, which we will use for this assignment. We will look at the Tweets with the colorful emojis again, but this time we are not going to filter the  textual content. Several toolkits or packages have been developed to process text data. In this assignment, we will rely on the [NLTK](https://www.nltk.org/) package (Natual Language Toolkit).\n",
    "\n",
    "In this assignment, you will: \n",
    "* Tokenize text data and extract ngrams and skipngrams.\n",
    "* Implement the calculation of edit distance. \n",
    "* Find near-duplicate sequences of a given piece of text.  \n",
    "\n",
    "First, let's load the dependencies and the Tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bb6e553f337c6b9398f650ab43bfe379",
     "grade": false,
     "grade_id": "cell-cf418579e93a7488",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import nltk\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9922be30a2c8524f964591774dc605b4",
     "grade": false,
     "grade_id": "cell-e11195263234723d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "with open('assets/tweets.txt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if len(line) > 0:\n",
    "            tweets.append(line.strip())\n",
    "tweets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "816cbf380261bbb3031afc8c86afa4a0",
     "grade": false,
     "grade_id": "cell-284c00fd413b9d2a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "To construct the sequence representation of the Tweet, we need to *tokenize* each Tweet into a sequence of language units, which in our case are words. For this assignment, we will use the TweetTokenizer API. For some languages, however, tokenization can be challenging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6e9d7f4fca3d5ca92c2c6f67169af40f",
     "grade": false,
     "grade_id": "cell-6a45dea40b149a57",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.casual.TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "26324d62bf9d759d92492a15565ec2ab",
     "grade": false,
     "grade_id": "cell-80cb7e3a4b3a4e36",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.tokenize(tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "14559c78c7376d59c7f2b2e9660bd7c8",
     "grade": false,
     "grade_id": "cell-73fd7f3fc7b6843a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "For a quick sanity check, we can calculate the word frequency and see which ones are the most frequently used. With the `Counter` object, we can easily obtain the most frequently used words and their numbers of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "662329091838227049e44792c7b27844",
     "grade": false,
     "grade_id": "cell-fc10bd9f0b788f2d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "unigram_counter = Counter()\n",
    "for tweet in tweets:\n",
    "    unigram_list = tokenizer.tokenize(tweet)\n",
    "    unigram_counter.update(unigram_list)\n",
    "unigram_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "491ff941b7c4ee1b2b465dcab078fb18",
     "grade": false,
     "grade_id": "cell-730d7652fbd54562",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "One common type of defined sequential patterns are $n$-grams. Particularly, 1-grams are often called \"unigrams\", 2-grams called bigrams, and 3-grams trigrams. Let's examine the bigrams of a Tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5d7cb74af105907c269a38c536c951b6",
     "grade": false,
     "grade_id": "cell-ec6dfb4fab22db93",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bigram_list = list(nltk.bigrams(tokenizer.tokenize(tweets[0])))\n",
    "bigram_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "754fd1c3f8855be63f16cd3abf87dfe5",
     "grade": false,
     "grade_id": "cell-c91511d320cb99fd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Note that each bigram is represented as a tuple of two strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f35364de8c7c7529059bc4e0269eecfb",
     "grade": false,
     "grade_id": "cell-2d9294576f9126f9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 1. Find the most frequent bigrams (20 pts)\n",
    "\n",
    "Please complete the `freq_bigram` function to find the $n$ most frequent bigrams. Your function should return a list of `top_n` tuples. Each of the tuples should contain a bigram tuple (such as ('üëç', 'üëè')) and its number of occurrence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a0b6e1c036ad774572f871b6a513a7f0",
     "grade": false,
     "grade_id": "cell-7c1d2e9dbae5fb22",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def freq_bigrams(tweets, top_n):\n",
    "    bigram_counter = Counter()\n",
    "    for tweet in tweets:\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    return bigram_counter.most_common(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cc14eed0adfb67f63da100414f44f554",
     "grade": false,
     "grade_id": "cell-9c0ffefe2324c16f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "freq_bigrams(tweets, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1e196071cd82e7b0d31ce070d5453580",
     "grade": true,
     "grade_id": "cell-7216282b01cb79fb",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This code block tests whether the `freq_bigrams` function is implemented correctly.\n",
    "# We hide some tests. Passing the displayed assertions does not guarantee full points.\n",
    "answer = freq_bigrams(tweets, 10)\n",
    "assert answer[0] == (('!', '!'), 1334)\n",
    "assert answer[8] == (('üéÇ', 'üç∞'), 276)\n",
    "\n",
    "answer2 = freq_bigrams(tweets[:5000], 5)\n",
    "assert answer2[0] == (('!', '!'), 682)\n",
    "assert answer2[2] == (('Happy', 'Birthday'), 290)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b9e3be8ab88e167e2eb3be25e915d289",
     "grade": false,
     "grade_id": "cell-c01ad957f4f2bd7b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Similarly, you can generate trigrams by calling the `nltk.trigrams` API. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cca47abe31a2d4f027aca4defdca62b7",
     "grade": false,
     "grade_id": "cell-49375454b56d1d2f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Exercise 2. Find the most frequent skipgrams (20 pts)\n",
    "\n",
    "In this exercise we will compute another commonly defined type of sequential patterns -- the skip-grams. Luckily this is also supported by NLTK. You can find the documentation [here](https://tedboy.github.io/nlps/generated/generated/nltk.skipgrams.html).\n",
    "\n",
    "Please implement the `freq_skipgrams` function to calculate the most frequently used $k$-skip-$n$-grams. Your function should return a list of `top_n` tuples. Each of the tuples should contain a $k$-skip-$n$-gram tuple (such as ('Happy', 'Birthday', 'üéÇ')) and its number of occurrences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6c473798cf66002bd51db598edeb1512",
     "grade": false,
     "grade_id": "cell-bbf383296f8a4dbe",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def freq_skipgrams(tweets, n, k, top_n):\n",
    "    skipgram_counter = Counter()\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d34f9d5ad331a1f980a252da7ab957ab",
     "grade": false,
     "grade_id": "cell-cbc8e21b75ac865d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "With this function, you can find the 10 most frequent 2-skip-trigram with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_skipgrams(tweets, n=3, k=2, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "43d725164477e906d669bcea97531642",
     "grade": true,
     "grade_id": "cell-e1ce15e33533958b",
     "locked": true,
     "points": 20,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test\n",
    "# This test cell contains hidden tests. Passing the displayed assertions does not guarantee full points.\n",
    "answer = freq_skipgrams(tweets, n=3, k=2, top_n=10)\n",
    "assert answer[0] == (('!', '!', '!'), 511)\n",
    "assert answer[3] == (('üéÇ', 'üéÇ', 'üéÇ'), 282)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c25e980eba215bcf85f08eeeb3e1b73d",
     "grade": false,
     "grade_id": "cell-ea2df02e9a9b5b4b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Ngrams and skipgrams are commonly used in text mining, biological sequence mining, and behavior mining tasks.  They are directly used as basis for tasks like phrase detection, named-entity detection, and motif detection, and they are also used as features for building machine learning models in general. Have fun using them in your own data analysis! "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_data_mining_i_v2_assignment4_part1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
